\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[margin=3cm]{geometry}
\usepackage[normalem]{ulem}
\usepackage{hyperref}
\usepackage[shortlabels]{enumitem}
\usepackage{mathtools, amsmath, amssymb, amsthm, mdframed, bbm, graphicx, float, physics, xcolor, cleveref}

\hypersetup{
    colorlinks   = true, %Colours links instead of ugly boxes
    urlcolor     = blue, %Colour for external hyperlinks
    linkcolor    = blue, %Colour of internal links
    citecolor   = red %Colour of citations
}

% Definition of numbered environments.
% Usage: \begin{theorem} ... \end{theorem}
% Remark has no numbering.
\theoremstyle{plain}
\newtheorem{question}{Question}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\theoremstyle{remark}
\newtheorem*{remark}{Remark}

% Question with box around it
\newenvironment{qbox}{\begin{mdframed}\begin{question}}{\end{question}\end{mdframed}}

% A proof with "solution" instead of "proof" and no QED symbol
\newenvironment{solution}{\begin{proof}[Solution]\renewcommand\qedsymbol{}}{\end{proof}}

% Some renewed commands
\renewcommand{\vec}{\mathbf}
\renewcommand{\emptyset}{\varnothing}
\renewcommand{\epsilon}{\varepsilon}
\renewcommand{\theta}{\vartheta}
\renewcommand{\phi}{\varphi}

% Frequently used math alphabets
\newcommand{\Bb}{\mathbb}
\newcommand{\Cal}{\mathcal}
\newcommand{\Bf}{\mathbf}
\newcommand{\Rm}{\mathrm}

% Frequently used letters in the blackboard alphabet
\newcommand{\CC}{\Bb C}
\newcommand{\NN}{\Bb N}
\newcommand{\PP}{\Bb P}
\newcommand{\QQ}{\Bb Q}
\newcommand{\RR}{\Bb R}
\newcommand{\EE}{\Bb E}

% Usage: \ang{...} is equivalent to \langle ... \rangle, while \ang*{...} is equivalent to \left\langle ... \right\rangle
% For other delimiters: use \qty from the physics package (i.e., \qty(...))
\DeclarePairedDelimiter{\ang}{\langle}{\rangle}
\DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}

% Frequently used commands
\newcommand{\T}{^\top} % Matrix transpose A\T
\newcommand{\C}{^\complement} % Set complement A\C
\renewcommand{\P}{^\perp}
\newcommand{\D}{^\dagger}
\newcommand\ceq\coloneqq % Definitions :=
\newcommand\pow{\Cal P} % Power sets
\newcommand\eps\epsilon
\newcommand\ind{\mathbbm 1} % Blackboard 1 for indicator functions
\newcommand\restr{\mathord\restriction}
\newcommand\TODO{{\color{red} TODO: }}
\newcommand\clos\overline

% Functions that appear frequently
\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\Int}{Int}
\DeclareMathOperator{\Span}{Span}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\newcommand\XX{\Cal X}
\newcommand\YY{\Cal Y}
\newcommand\UU{\Cal U}
\newcommand\VV{\Cal V}
\newcommand\LL{\Cal L}
\newcommand\KK{\Cal K}
\newcommand\BB{\Cal B}
\newcommand\JJ{\Cal J}
\newcommand\LLL{\Bb L}
\newcommand\DD{\Cal D}
\newcommand\FF{\Cal F}
\newcommand\Pp{\Cal P}
\DeclareMathOperator\Dom{\Cal D}
\DeclareMathOperator\Nul{\Cal N}
\DeclareMathOperator\Ran{\Cal R}
\DeclareMathOperator\TV{TV}
\DeclareMathOperator\BV{BV}
\DeclareMathOperator\Prob{Prob}
\newcommand\pro{_\Rm{prod}}

\newcommand\cw\rightharpoonup
\newcommand\cws{\overset{*}{\rightharpoonup}}
\newcommand\rext{\overline\RR}
\newcommand\pt\partial
\DeclareMathOperator\dom{dom}

\title{Inverse Problems --- Example Sheet 3}
\author{Lucas Riedstra}
\begin{document}
\maketitle

\begin{question}
	Let $(\Omega, \FF)$ be a measurable space and $\mu, \nu, \rho$ be $\sigma$-finite measures on $(\Omega, \FF)$. Prove the following statements.
	\begin{enumerate}[(a)]
		\item Let $\nu \ll \mu$ and $a \geq 0$. Then, $a \cdot \nu \ll \mu$ and $\dv{a\cdot \nu}{\mu} = a \dv{\nu}{\mu}$ ($\mu$-a.e.). 
		\item Let $\nu \ll \mu$ and $\rho \ll \mu$. Then, $\nu + \rho \ll \mu$ and $\dv{\nu + \rho}{\mu} = \dv{\nu}{\mu} + \dv{\rho}{\mu}$ ($\mu$-a.e.). 
		\item Let $\rho \ll \nu$ and $\nu \ll \mu$. Then, $\rho \ll \mu$ and $\dv{\rho}{\mu} = \dv{\rho}{\nu} \cdot \dv{\nu}{\mu}$ ($\mu$-a.e.). 
	\end{enumerate}
\end{question}

\begin{proof}
	\begin{enumerate}[(a)]
		\item We have, for $F \in \FF$, that $\mu(F) = 0 \implies \nu(F) = 0 \implies (a\cdot \nu)(F) = 0$. Furthermore, we have
		\[
		(a \cdot \nu)(F) = a \cdot (\nu(F)) = a \cdot \int_F \dv{\nu}{\mu} \dd{\mu} = \int_F \qty(a \dv{\nu}{\mu}) \dd{\mu}, 
		\]
		which proves the Radon-Nikodym derivative of $a\cdot\nu$ is $a \dv{\nu}{\mu}$. 
		
		\item We have, for $F \in \FF$, that $\mu(F) = 0 \implies \nu(F) = 0 \text{ and } \rho(F) = 0$ and therefore also $(\nu + \rho)(F) =0$. Furthermore, we have
		\[
		(\nu + \rho)(F) = \nu(F) + \rho(F) = \int_F\dv{\nu}{\mu} \dd{\mu} + \int_F \dv{\rho}{\mu} \dd{\mu} = \int_F \qty(\dv{\nu}{\mu} + \dv{\rho}{\mu}) \dd{\mu}, 
		\]
		which proves the Radon-Nikodym derivative of $\nu + \rho$ is $\dv{\nu}{\mu} + \dv{\rho}{\mu}$. 
		
		\item We have, for $F \in \FF$, that $\mu(F) = 0\implies \nu(F) = 0 \implies \rho(F) = 0$. Furthermore, we have
		\[
		\rho(F) = \int_F \dv{\rho}{\nu} \dd{\nu} \overset\star= \int_F \dv{\rho}{\nu} \dv{\nu}{\mu} \dd{\mu},
		\]
		which proves the Radon-Nikodym derivative of $\rho$ is $\dv{\rho}{\nu} \dv{\nu}{\mu}$. Here, $\star$ follows from the fact that if a measure $\nu$ has $\mu$-density $g$, then $\int_\XX f \dd{\nu} = \int_\XX fg \dd{\mu}$ for all $f \geq 0$ --- this can be proved first for simple functions, and then extended to nonnegative integrable functions. 
	\end{enumerate}
\end{proof}

\begin{question}
	Let $(\Omega, \FF, \PP)$ be a probability space, and $U, U' \colon (\Omega, \FF) \to (\RR, \BB\RR)$, $Y \colon (\Omega, \FF) \to (\YY, \BB\YY)$ random variables. Moreover, let $U$ and $U'$ be integrable. Prove the following statements:
	\begin{enumerate}[(a)]
		\item Let $c \in \RR$ and $\PP(U = c) = 1$. Then, $\EE[U \mid Y = y] = c$  ($\PP(Y \in \cdot)$-a.s.). 
		\item Let $c \in \RR$. Then $\EE[cU \mid Y = y] = c \EE[U \mid Y = y]$ ($\PP(Y \in \cdot)$-a.s.).
		\item $\EE[U + U' \mid Y = y] = \EE[U \mid Y = y] + \EE[U' \mid Y = y]$ ($\PP(Y \in \cdot)$-a.s.). 
	\end{enumerate}
\end{question}

\begin{proof}
	Let $F \in \BB\YY$. 
	
	\begin{enumerate}[(a)]
		\item We have for all $F$
		\[
		%\int_F \EE[U \mid Y = y] \PP(Y \in \dd{y}) = 
		\int_\qty{Y \in F} U \dd{\PP} = \int_\qty{Y \in F} c \dd{\PP} = c \PP(Y \in F) = \int_F c \PP(Y \in \dd{y}).
		\]
		\item We have for all $F$
		\[
		\int_\qty{Y \in F} cU \dd{\PP} = c \int_\qty{Y \in F} U \dd{\PP} = c \int_F \EE[U \mid Y = y] \PP(Y \in \dd{y}) = \int_F c\EE[U \mid Y = y] \PP(Y \in \dd{y}).
		\]
		
		\item We have for all $F$
		\begin{align*}
		\int_\qty{Y \in F} \qty(U + U') \dd{\PP} &= \int_\qty{Y \in F} U \dd{\PP} + \int_\qty{Y \in F} U' \dd{\PP} \\
		&= \int_F \EE[U \mid Y = y] \PP(Y \in \dd{y}) + \int_F \EE[U' \mid Y = y] \PP(Y \in \dd{y}) \\
		&= \int_F \qty( \EE[U \mid Y = y] + \EE[U' \mid Y = y]) \PP(Y \in \dd{y}).
		\end{align*}
	\end{enumerate}
\end{proof}

\begin{question}
	Let $a \in \RR\setminus \qty{0}$. We consider the inverse problem $au + n = f_n$, where $u \in \RR$ is the unknown parameter, $n \in \RR$ is measurement noise, and $f_n \in \RR$ is observed data. We assume that the noise and prior are Gaussian, $N \sim \Rm N(0, \gamma^2)$ and $U \sim \Rm N(m_0, \sigma_0^2)$, where $\gamma^2 > 0, \sigma_0^2 > 0$. Assume that the likelihood is given by
	\[
	L(f_n \mid u) \ceq \frac1{\sqrt{2\pi\gamma^2}} \exp(- \frac{(au - f_n)^2}{2\gamma}).
	\]
	\begin{enumerate}
		\item[(i)] Compute the posterior measure $\PP(U \in \cdot \mid aU + N = f_n)$. 
	\end{enumerate}
Next, we assume that we take $N$ independent observations of the data, i.e., we consider the likelihood
\[
L\qty(f_n^{(1:M)} \mid u) \ceq \prod_{i=1}^M \frac{1}{\sqrt{2\pi \gamma^2}} \exp(- \frac{(au - f_n^{(i)})^2}{2\gamma^2}), 
\]
where $f_n^{(i)} \in \RR$. 
\begin{enumerate}
	\item[(ii)] Compute the posterior measure $N(m_M, \sigma_M^2) \ceq \PP(U \in \cdot \mid aU + N = f_n^{(i)} (i = 1, \dotsc, M))$. 
	\item[(iii)] Replace the data $f_n^{(1:M)}$ in the posterior by the random vector
	\[
	F \ceq \mqty(a u\D \\ \vdots \\ a u\D) + \eta,
	\]
	where $\eta \sim \Rm N(0, \gamma^2 I)$ for some $u\D \in \RR$ and study the asymptotic behaviour of $\EE[m_M], m_M, \sigma_M^2$ as $M \to\infty$. How do you explain your findings?
\end{enumerate}
\end{question}

\begin{proof}
	\begin{enumerate}[(i)]
		\item 
		%		We will assume the conditions for Bayes' theorem hold, and now we must compute 
		%		\[
		%		\frac{L(f_n \mid U)}{\int_{-\infty}^\infty L(f_n \mid v) \dd{v}}.
		%		\] 
		We have, with $C = (2\pi\gamma^2)^{-1/2}$, 
		\begin{align*}
			\int_{-\infty}^\infty L(f_n \mid v) \dd{v} &=  C \int_{-\infty}^\infty \exp\qty(- \frac{(av - f_n)^2}{2\gamma^2}) \dd{v} = \frac Ca \int_{-\infty}^\infty \exp(- \frac{(v - f_n)^2}{2\gamma^2}) \dd{v} = \frac1a. 
		\end{align*} 
		Thus we have
		\[
		\dv{\mu_\Rm{post}}{\mu_0} \qty(u)= \frac aC \exp(- \frac{(au - f_n)^2}{2\gamma^2}) = \frac aC \exp(- \frac{(u - f_n/a)^2}{2(\gamma / a)^2}),
		\]
		which is the density of an $N(f_n/a, \gamma^2/a^2)$ distribution. 
		
		By question 1c, we have
		\begin{align*}
			\dv{\mu_\Rm{post}}{\lambda} \qty(u)&= \dv{\mu_\Rm{post}}{\mu_0} \qty(u)\dv{\mu_0}{\lambda}\qty(u),
		\end{align*}
		which is (up to a constant) the product of an $N(f_n/a, \gamma^2/a^2)$ density with an $N(m_0, \sigma_0^2)$ density. 
		
		For this, we can use the following lemma:
		\begin{mdframed}
		\begin{lemma}
			Let $f_{\mu_1, \sigma_1}, f_{\mu_2, \sigma_2}$ be the density functions of $\Rm N(\mu_1, \sigma_1^2), \Rm N(\mu_2, \sigma_2^2)$ distributions respectively. Then the product $f_{\mu_1, \sigma_1} f_{\mu_2, \sigma_2}$ is proportional to an $f_{\mu\pro, \sigma\pro}$ density, where
			\[
			\mu\pro \ceq \frac{\mu_1\sigma_2^2 + \mu_2\sigma_1^2}{\sigma_1^2 + \sigma_2^2}, \quad \sigma\pro^2 \ceq \frac{\sigma_1^2\sigma_2^2}{\sigma_1^2 + \sigma_2^2}. 
			\]
		\end{lemma}
	
	\begin{proof}
		Since we are discussing proportionality, we only care about the exponents. We have
		\begin{align*}
			\frac{(x - \mu_1)^2}{\sigma_1^2} + \frac{(x - \mu_2)^2}{\sigma_2^2} &= \frac{(\sigma_1^2 + \sigma_2^2) x^2 - 2 (\mu_1\sigma_2^2 + \mu_2 \sigma_1^2)x  +  \mu_1^2\sigma_2^2 + \mu_2^2\sigma_1^2}{\sigma_1^2\sigma_2^2} \\
			&= \frac{x^2 - 2 \frac{\mu_1\sigma_2^2 + \mu_2\sigma_1^2}{\sigma_1^2 + \sigma_2^2} x + \frac{\mu_1^2\sigma_2^2 + \mu_2^2\sigma_1^2}{\sigma_1^2 + \sigma_2^2}}{\frac{\sigma_1^2\sigma_2^2}{\sigma_1^2 + \sigma_2^2}} \\
			&= \frac{\qty(x - \frac{\mu_1\sigma_2^2 + \mu_2\sigma_1^2}{\sigma_1^2 + \sigma_2^2})^2}{\frac{\sigma_1^2\sigma_2^2}{\sigma_1^2 + \sigma_2^2}} + C,
		\end{align*}
	where $C$ is some constant independent of $x$. The claim follows. 
	\end{proof}
\end{mdframed}
Plugging in our values we can compute the posterior density: it is an $\Rm N(\mu\pro, \sigma\pro^2)$ density where
\begin{align*}
	\mu\pro &= \frac{\frac{f_n\sigma_0^2}{a} + \frac{m_0\gamma^2}{a^2}}{\frac{\gamma^2}{a^2} + \sigma_0^2}  = \frac{a f_n \sigma_0^2 + m_0\gamma^2}{\gamma^2 + a^2\sigma_0^2}, \\
	\sigma\pro^2 &= \frac{\frac{\sigma_0^2\gamma^2}{a^2}}{\frac{\gamma^2}{a^2} + \sigma_0^2} = \frac{\sigma_0^2 \gamma^2}{\gamma^2 + a^2\sigma_0^2}. 
\end{align*}%		We can compute the product density, and it is proportional to a Gaussian density with parameters
%		\[
%		\mu_c \ceq \frac{1}{\frac{a^2}{\gamma^2} + \frac{1}{\sigma_0^2}} \qty(\frac{a f_n}{\gamma^2} + \frac{m_0}{\sigma_0^2}), \quad \sigma_c^2 \ceq  \frac{1}{\frac{a^2}{\gamma^2} + \frac{1}{\sigma_0^2}} . 
%		\]
%		Therefore, the product density is an $N(\mu_c, \sigma_c^2)$ density, from which the posterior measure follows. 

\item We get similar computations as in the previous part, except that we have to compute the product of $N + 1$ densities, namely $\Rm N(f_n^{(1)}/a, \gamma^2/a^2), \dotsc, \Rm N(f_n^{(N)}/a, \gamma^2/a^2), \Rm N(m_0, \sigma_0^2)$. 
Note that in the previous lemma, if $\sigma_1^2 = \sigma_2^2  = \sigma^2$, the formula gives
\[
\mu\pro = \frac12(\mu_1 + \mu_2), \quad \sigma\pro = \frac{\sigma^2}{2}, 
\]
and this generalises: for $N$ observations we get 
\[
\mu\pro^{(n)} = \frac1n (\mu_1 + \dotsb + \mu_n) \eqqcolon \bar\mu, \quad\sigma\pro^{(n)} = \frac{\sigma^2}{n}. 
\]
This shows that the product of the $\Rm N(f_n^{(1)}/a, \gamma^2/a^2), \dotsc, \Rm N(f_n^{(N)}/a, \gamma^2/a^2)$ densities is proportional to a $\Rm N(\bar{f_n}/a, \gamma^2/(na^2))$ distribution, where $\bar f_n$ is the average of $f_n^{(1)}, \dotsc, f_n^{(n)}$. 

When we multiply this with prior density $\Rm N(m_0, \sigma_0^2)$, we get
\begin{align*}
	\mu_M &= \frac{\frac{\bar f_n \sigma_0^2}{a} + \frac{m_0\gamma^2}{na^2}}{\frac{\gamma^2}{na^2} + \sigma_0^2} = \frac{n a \bar f_n\sigma_0^2 + m_0\gamma^2}{\gamma^2 + na^2\sigma_0^2}, \\
	\sigma_M^2 &= \frac{\frac{\sigma_0^2\gamma^2}{na^2}}{\frac{\gamma^2}{na^2} + \sigma_0^2} = \frac{\sigma_0^2\gamma^2}{\gamma^2 + na^2\sigma_0^2}. 
\end{align*}

\item Note that $\bar F = a u\D + \bar\eta$, and we know from elementary probability theory that if $\eta \sim N(0, \gamma^2I)$, then for the average $\bar\eta$ we have $\bar \eta \sim N(0, \gamma^2/n)$. 
We get
\begin{align*}
	\EE[m_M]  &= \EE\qty[ \frac{n a (au\D + \bar\eta) \sigma_0^2 + m_0\gamma^2}{\gamma^2 + na^2\sigma_0^2}] = \frac{na^2 u\D \sigma_0^2 + m_0\gamma^2}{\gamma^2 + na^2\sigma_0^2} \overset{n\to\infty}\to  u\D,
\end{align*}
so in the limit $n \to\infty$, we have $\EE[m_M] \to u\D$, which seems reasonable: the more observations we get, the less our prior assumptions are taken into account. 

By the law of large numbers, we have
\[
m_M = \frac{na^2\sigma_0^2 u\D + m_0\gamma^2}{n a^2 \sigma_0^2 + \gamma^2} + \frac{na\sigma_0^2 \bar\eta + m_0\gamma^2}{na^2\sigma_0^2\gamma^2} \to u\D, 
\]
since $\bar\eta \to 0$ as $n\to\infty$ by the law of large numbers. 

Finally, since $\sigma_M^2$ is independent of the data (it depends only on the likelihood and the prior), we can simply let $n\to\infty$ in our expression for $\sigma_M^2$ and see $\sigma_M^2 \to 0$, which also makes sense: the more observations we get, the less variance we have. 
	\end{enumerate}
\end{proof}

\begin{question}
	Let $(\Omega, \FF)$ and let $\Prob(\Omega, \FF)$ be the space of probability measures on $(\Omega, \FF)$. 
	\begin{enumerate}[(i)]
		\item Show that $d_{\TV} \colon \Prob(\Omega, \FF)^2 \to [0, \infty) \colon (\mu, \nu) \mapsto \sup_{F \in \FF} \abs{\mu(F) - \nu(F)}$ is a metric on $\Prob(\Omega, \FF)$. 
		
		\item Let $\mu, \nu \in \Prob(\Omega, \FF)$ and $\rho$ be a $\sigma$-finite measure with $\mu, \nu \ll\rho$. Show that
		\[
		d_{\TV} (\mu, \nu) = \frac12\int_\Omega \abs{\dv{\mu}{\rho} - \dv{\nu}{\rho}} \dd{\rho}. 
		\]
		
		\item Let $\KK \ceq \qty{h \colon (\Omega, \FF) \to (\RR, \BB\RR) \colon \sup_{\omega \in \Omega} \abs{h(\omega)} \leq 1}$ and $\mu, \nu \in \Prob(\Omega, \FF)$. Show that
		\[
		d_\Rm{TV}(\mu, \nu) = \sup_{h \in \KK} \frac12 \abs{\int_\Omega h \dd{\mu} - h\dd{\nu}}. 
		\]
		
		\item Let $\Omega$ be a topological space and $(\Omega, \FF) \ceq (\Omega, \BB\Omega)$. Let $(\mu_n)_{n\in\NN} \in \Prob(\Omega, \FF)^\NN$ and $\mu \in \Prob(\Omega, \FF)$. Show that 
		\[
		\lim_{n\to\infty} d_\Rm{TV}(\mu_n, \mu) = 0 \implies \mu_n \to \mu \text{ weakly, as } n \to\infty. 
		\]
		
		\item Show that the converse of (iv) is in general not true. 
	\end{enumerate}
\end{question}

\begin{proof}
	\begin{enumerate}[(i)]
		\item We check the metric definition. It is clear that $d_\Rm{TV}$ is nonnegative and symmetric. Furthermore, we have
		\[
		d_\Rm{TV}(\mu, \nu) = 0 \implies \sup_{F\in \FF} \abs{\mu(F) - \nu(F)} = 0 \implies \mu(F) = \nu(F) \text{ for all } F \in \FF \implies \mu = \nu.
		\]
		Finally, if $\mu, \nu, \rho \in \Prob(\Omega, \FF)$, then by the ``normal'' triangle inequality we have
		\begin{align*}
			d_\Rm{TV}(\mu, \rho) &= \sup_{F \in \FF} \abs{\mu(F) - \rho(F)} = \sup_{F \in \FF} \abs{\mu(F) - \nu(F) + \nu(F) - \rho(F)} \\
			&\leq \sup_{F \in \FF} \qty(\abs{\mu(F) - \nu(F)} + \abs{\nu(F) - \rho(F)}) \\
			&\leq \sup_{F \in \FF} \abs{\mu(F) - \nu(F)} + \sup_{F\in \FF} \abs{\nu(F) - \rho(F)} \\
			&= d_\Rm{TV}(\mu, \nu) + d_\Rm{TV}(\nu, \rho). 
		\end{align*}
	
	\item Write $A = \qty{x \in \Omega \mid \dv{\mu}{\rho}\qty(x) > \dv{\nu}{\rho}\qty(x)}$ and $B = \qty{x \in \Omega \mid \dv{\mu}{\rho}\qty(x) < \dv{\nu}{\rho}\qty(x)}$. 
	Note that for any $X \subseteq A$ we have $\mu(X) \geq \nu(X)$ while for any $X \subseteq B$ we have $\mu(X) \leq \nu(X)$.  
	
	Also note that $\mu(A) - \nu(A) = \nu(B) - \mu(B)$. 
	Therefore, we have
	\begin{align*}
	d_\Rm{TV}(\mu, \nu) &= \sup_{F \in \FF} \abs{\mu(F) - \nu(F)} \\
	&= \sup_{F \in \FF} \abs{\mu(F \cap A) - \nu(F \cap A) + \mu(F \cap B) - \nu(F \cap B)} \\
	&\leq \sup_{F \in \FF} \max\qty{\mu(F \cap A) - \nu(F \cap A), \nu(F \cap B) - \mu(F \cap B)} \\
	&\leq \sup_{F \in \FF} \max\qty{\mu(A) - \nu(A), \nu(B) - \mu(B)} \\
	&= \mu(A) - \nu(A). 
	\end{align*}

	Looking at the integral in the question, we see
	\begin{align*}
		\frac12\int_\Omega \abs{\dv{\mu}{\rho} - \dv{\nu}{\rho}} \dd{\rho} &=  \frac12 \qty(\int_A \qty(\dv{\mu}{\rho} - \dv{\nu}{\rho}) \dd{\rho} - \int_B \qty(\dv{\mu}{\rho} - \dv{\nu}{\rho}) \dd{\rho}) \\
		&= \frac12\qty(\mu(A) - \nu(A) - \mu(B) + \nu(B)) \\
		&= \mu(A) - \nu(A). 
	\end{align*}
We conclude
\[
d_\Rm{TV}(\mu, \nu) = \mu(A) - \nu(A) = \frac12\int_\Omega \abs{\dv{\mu}{\rho} - \dv{\nu}{\rho}} \dd{\rho}.
\]

\item Let $\rho = \mu + \nu$, then we have $\mu \ll\rho$ and $\nu \ll \rho$, and $\rho$ is $(\sigma$-)finite. Define $A$ and $B$ as in the solution to the previous exercise, then we have for $h \in \KK$ that
\begin{align*}
	\frac12 \abs{\int_\Omega h \dd{\mu} - \int_\Omega h \dd{\nu}} &= \frac12 \abs{\int_\Omega h\qty(\dv{\mu}{\rho} - \dv{\nu}{\rho}) \dd{\rho}} \\
	&\leq \frac12 \int_\Omega \abs{\dv{\mu}{\rho} - \dv{\nu}{\rho}}\dd{\rho} \\
	&= \frac12 \int_A \qty(\dv{\mu}{\rho} - \dv{\nu}{\rho}) \dd{\rho} + \frac12 \int_B \qty(\dv{\nu}{\rho} - \dv{\mu}{\rho}) \dd{\rho} \\
	&= \mu(A) - \nu(A) = d_\Rm{TV}(\mu, \nu). 
\end{align*}
Furthermore, equality can be obtained by letting $h = \ind_A - \ind_B \in \KK$, which concludes the proof. 

\item Suppose that $d_\Rm{TV}(\mu_n, \mu) \to 0$, and let $g \colon (\Omega, \FF) \to (\RR, \BB\RR)$ be continuous and bounded. Since $g$ is bounded, without loss of generality we can assume $\sup_{\omega \in \Omega} \abs{g(\omega)} \leq 1$ (otherwise we divide by a constant). Now, by the previous exercise we have
\[
d_\Rm{TV}(\mu_n, \mu) \geq \frac12 \abs{\int_\Omega g \dd{\mu} - \int_\Omega g \dd{\mu_n}}, 
\] 
and since $d_\Rm{TV}(\mu_n, \mu) \to 0$, we conclude that $\abs{\int_\Omega g \dd{\mu} - \int_\Omega g \dd{\mu_n}} \to 0$, or equivalently that $\int_\Omega g \dd{\mu_n} \to \int_\Omega g \dd{\mu}$. Since $g$ was arbitrarily chosen, we conclude that $\mu_n \to \mu$ weakly. 

\item Let $\mu_n$ be the measure on $(\RR, \BB\RR)$ corresponding to the uniform distribution on $[-\frac1n, \frac1n]$ with density function $f(x) = \frac n2 \cdot  \ind_{[-\frac1n, \frac1n]}$, and let $\mu \ceq \delta_0$. We claim $\mu_n \to \mu$ weakly. 

To prove this claim, let $g \colon (\RR, \BB\RR) \to (\RR, \BB\RR)$ be continuous and bounded, and let $\eps > 0$. Choose $n$ large enough such that, on $[-1/n, 1/n]$, $g$ takes values in $[g(0) - \eps, g(0) + \eps]$. Then we have 
\[
\int_\RR g \dd{\mu_n} = \frac n2 \int_{-1/n}^{1/n} g(x) \dd{x} \in [g(0) - \eps, g(0) + \eps], 
\]
and since $\eps$ was randomly chosen, we conclude $\int_\RR g \dd{\mu_n} \to g(0) = \int_\RR g \dd{\delta_0}$. 

However, it is immediate that $d_\Rm{TV}(\mu_n, \mu)$ does not converge to 0, since $\mu_n(\qty{0}) = 0$ for all $n$ while $\mu(\qty{0}) = 1$. 
	\end{enumerate}
\end{proof}

\begin{question}
	Let $\mu$ be a probability measure on $(\RR, \BB\RR)$ with cumulative distribution function (cdf) $F \colon \RR \to [0, 1] \colon x \mapsto \mu((-\infty, x])$, for $x \in \RR$. 
	\begin{enumerate}[(i)]
		\item Let $Q \colon (0, 1) \to \RR$ be the quantile function of $\mu$, i.e., $Q(y) \ceq \inf\qty{x \in \RR \mid F(x) \geq y}$. Moreover, let $U \sim \Rm{Unif}(0, 1) \ceq \lambda_1(\cdot \cap (0, 1))$ be a uniformly distributed random variable on the interval $(0, 1)$. Show that $\PP(Q(U) \in \cdot) = \mu$. (Hint: you may use the fact that probability measures on $(\RR, \BB\RR)$ are uniquely determined by their CDF). 
		\item Derive the quantile function for the exponential distribution, i.e., the distribution with cdf $F(x) \ceq 1 - \exp(-\lambda x)$ for some $\lambda > 0$. 
		
		\item Use the idea from (i) and your quantile function from (ii) to generate independent samples (i.e., realisations of random variables) with $\lambda = 1$. 
		\begin{enumerate}[(a)]
			\item Plot the cdf of the exponential distribution along with the empirical cdf of 
			\[
			M \in \qty{10, 100, 1000, 10000}
			\]
			of your samples. (Hint: you can use the \verb|ecdf| command to obtain a representation of your empirical cdf). What do you observe?
			\item Compute the sample mean $\bar X_M$ of your exponentially distributed samples $X_1, \dotsc, X_m$; for $M = \qty{2^n \mid n = 1, \dotsc, 20}$. What do you observe? 
		\end{enumerate}
	
		\item Repeat (iii)(b) using the quantile function $Q'(y) \ceq \tan(\pi(y - 0.5))$ ($y \in \RR$). What do you observe?
		
		\item Let $X_1, \dotsc, X_M \sim \mu$ be i.i.d., and assume that $\Var(X_1)$ is finite. Show that
		\[
		\EE\qty[\qty(\EE[X_1] - \bar X_M)^2] = \frac{\Var(X_1)}{M}. 
		\]
		\item Can you recover the rate from (v) in your experiments in (iii)? What could be the issue in (iv)? 
	\end{enumerate}

\end{question}

\begin{proof}
	\begin{enumerate}[(i)]
		\item Since probability measures on $(\RR, \BB\RR)$ are uniquely determined by their CDF, we must show that the CDF of $\mu$ agrees with the CDF of $\PP(Q(U) \in \cdot)$, i.e., for all $x \in \RR$
		\[
		F(x) = \mu((-\infty, x]) = \PP(Q(U) \in (-\infty, x]). 
		\]
		For this, note that
		\begin{align*}
			\PP(Q(U) \in (-\infty, x]) = \PP(Q(U) \leq x) \overset\star= \PP(U \leq F(x)) = F(x), 
		\end{align*}
	
	\item For the exponential distribution, the cdf $F$ is an invertible function between $(0, \infty)$ and $(0, 1)$, so the quantile function is just the inverse. We have
	\[	
	y = 1 - e^{-\lambda x} \iff e^{-\lambda x} = 1 - y \iff -\lambda x = \ln(1 - y) \iff x = -\frac{\ln(1 - y)}{\lambda}, 
	\]
	so the quantile function is given by $Q(y) = -\frac{\ln(1 - y)}{\lambda}$. 
	
	\item
	
	\begin{enumerate}[(a)]
		\item From approximately $M = 1000$, the empirical CDF aligns almost exactly with the true cdf.
		\item Keeps getting closer to 1. 
	\end{enumerate}

\item The means are all over the place and don't seem to converge to anything.

\item We have 
\begin{align*}
	\EE\qty[\EE[X_1]^2 - 2\EE[X_1] \bar X_M + \bar{X_M}^2] &= \EE[X_1]^2 - 2\EE[X_1] \EE[\bar X_M] + \EE[\bar X_M^2] \\
	&= \EE[X_1]^2 - 2\EE[X_1]^2 + \frac1{M^2} \sum_{ij} \EE[X_i X_j] \\
	&= - \EE[X_1]^2 + \frac1M \EE[X_1^2] + \frac{M-1}{M} \EE[X_1]^2 \\
	&= \frac{\EE[X_1^2] - \EE[X_1]^2}{M} = \frac1M \Var(X_1).  
\end{align*}

\item In (iv), the issue is that the distribution does not have finite mean or variance. 
	\end{enumerate}

\end{proof}
\end{document}