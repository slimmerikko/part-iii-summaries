\section{Bayesian probability and statistics}
\subsection{Motivation}
Let $\XX, \YY$ be separable Banach spaces and $A \colon \XX\to\YY$ a measurable operator (possibly nonlinear). We consider the inverse problem
\[
\text{Find $u \in \XX$ such that } A(u) + n = f_n,
\]
where $f_n \in \YY$ is data and $n \in \YY$ is noise. 

In Bayesian probability theory, we attempt to give an estimate for $u$ while also commenting on the uncertainty left in $u$ after measurement. The main idea is to \textbf{model uncertain parameters as random variables}. In this case, we assume the noise $n$ and the parameter $u$ are random variables $N, U$. The distribution of $N$ is usually known, while the distribution of $U$ (called the \emph{prior distribution $\mu_0 = \PP(U \in \cdot)$}) describes our prior knowledge of $u$. We then observe data $f_n$, which is described as an occurrence of the event $\qty{f_n = A(U) + N}$. After our observation, we replace the distribution $\mu_0$ by the distribution
\[
\mu_\Rm{post} \ceq \PP(U \in \cdot \mid f_n = A(U) + N). 
\]

\subsection{Measure theory}
\begin{definition}
	Let $\Omega$ be a topological space, and let $\Cal O$ be the topology on $\Omega$. Then the $\sigma$-algebra generated by $\Cal O$ is denoted $\BB\Omega$ and called the \emph{Borel $\sigma$-algebra} on $\Omega$. 
\end{definition}
Note that we do not explicitly state the topology used when writing $\BB\Omega$, but this is always clear from context. 

\begin{definition}
	Let $(\Omega, \FF, \mu)$ be a measure space, $(\Omega', \FF')$ a measurable space, and $g \colon (\Omega, \FF) \to (\Omega', \FF')$ measurable. Then, the map $\mu \circ g^{-1} = \mu(g \in \cdot)$ defines a measure on $(\Omega', \FF')$ called the \emph{pushforward measure}. 
	
	Note that if $\mu$ is a probability measure, then so is $\mu(g \in \cdot)$. 
\end{definition}

\begin{definition}
	Let $(\Omega, \FF, \mu)$ be a measure space and let $g \colon (\Omega, \FF) \to (\RR, \BB \RR)$ be measurable and non-negative. Then the map 
	\[
	\nu \colon \FF \to [0, \infty] \colon F \mapsto \int_F g \dd{\mu}
	\]
	defines a measure on $(\Omega, \FF)$, called the \emph{measure with ($\mu$-)density $g$}. If $\nu$ is a probability measure, $g$ is called a \emph{($\mu$-)probability density}. 
\end{definition}

\begin{definition}
	Let $(\Omega, \FF)$ be a measurable space and $\mu, \nu$ two measures on $\Omega$. Then $\nu$ is called \emph{absolutely continuous} with respect to $\mu$, denoted $\nu \ll \mu$, if \[\mu(F) = 0 \implies \nu(F) =0 \qquad\text{for all $F \in \FF$}. 
\]
\end{definition}

\begin{theorem}[Radon-Nikodym]
	Let $(\Omega, \FF)$ be a measurable space and let $\mu, \nu$ be $\sigma$-finite measures on $(\Omega, \FF)$. Then, the following are equivalent:
	\begin{enumerate}
		\item $\nu \ll \mu$;
		\item There is a measurable $g \colon (\Omega, \FF) \to (\RR, \BB\RR)$, with
		\[
		\nu(F) = \int_F g \dd{\mu} \qquad\text{for all $F \in \FF$}. 
		\]
	\end{enumerate}
The function $g$ is $\mu$-a.e.\ unique, and is called the \uline{Radon-Nikodym derivative}, denoted $\frac{\dd{\nu}}{\dd{\mu}}$. 
\end{theorem}

\subsection{Conditional probability}
We will consider $(\Omega, \FF, \PP)$ as underlying probability space for any random variable, and assume $\Omega$ is separable and completely metrisable (this is also called \emph{Polish}) and $\FF = \BB\Omega$. We also write
\[
\EE[\phi] \ceq \int_\Omega \phi \dd{\PP}
\]
for any $\phi \in L^1(\Omega)$. 

\begin{theorem}
	Let $U \colon (\Omega, \FF) \to (\RR, \BB\RR)$ and $Y \colon (\Omega, \FF) \to (\YY, \BB\YY)$ be random variables and let $U$ be integrable. Then there exists a measurable function $h \colon (\YY, \BB\YY) \to(\RR, \BB\RR)$ such that
	\[
	\int_F h(y) \PP(Y \in \dd{y}) = \int_{\qty{Y\in F}} U \dd{\PP} \qquad\text{for all $F \in \FF$}. 
	\]
	The function $h$ is $\PP(Y \in \cdot)$-a.s.\ unique.
\end{theorem}

\begin{definition}
	For $y \in \YY$, we call $h(y)$ (from the previous theorem) the \uline{conditional expectation of $U$ given $Y = y$}, denoted $h(y) \eqqcolon \EE[U \mid Y = y]$ (which is well-defined up to $\PP(Y \in \cdot)$ null sets). 
	
	%For an event $F \in \FF$, we define the \emph{probability of $F$ given $Y = y$} as $\EE[\ind_F \mid Y = y]$.
\end{definition}

\begin{definition}
	Let $(\Omega, \FF)$, $(\Omega', \FF')$ be measurable spaces and $M \colon \Omega \times \FF' \to [0, 1]$. Then $M$ is called a \emph{Markov kernel} if
	\begin{enumerate}
		\item $M(\omega, \cdot)$ is a probability measure for all $\omega \in \Omega$;
		\item $M(\cdot, F')$ is measurable for all $F' \in \FF'$. 
	\end{enumerate}
\end{definition}

It can be shown that $(y, F) \mapsto \EE[\ind_F \mid Y= y]$ (which represents the probability of $F$ given $Y = y$) is a Markov kernel. This is clarified in the following theorem:

\begin{theorem}
Let $U \colon (\Omega, \FF) \to (\XX, \BB\XX)$ and $Y \colon (\Omega, \FF) \to (\YY, \BB\YY)$ be random variables. Then there exists a Markov kernel from $(\YY, \BB\YY)$ to $(\XX, \BB\XX)$ with
\[
\int_F M(y, F') \PP(Y \in \dd{y}) = \PP(\qty{Y\in F} \cap \qty{U \in F'}) \qquad \text{for all $F \in \BB\YY$ and $F' \in \BB\XX$}. 
\]
Furthermore, $M$ is $\PP(Y \in \cdot)$-a.s.\ unique, and it is called the \uline{conditional probability distribution of $U$ given $Y = y$}. We write $M(y, F) \ceq \PP(U \in F \mid Y = y)$. 
\end{theorem}

Furthermore, any Markov kernel represents the conditional probability measure of some random variable:
\begin{theorem}
	Let $M \colon \Omega' \times \FF'' \to [0, 1]$ be a Markov kernel from $(\Omega', \FF')$ to $(\Omega'', \FF'')$. Then there is an underlying probability space $(\Omega, \FF, \PP)$ and random variables $X' \colon \Omega \to \Omega'$, $X'' \colon \Omega \to \Omega''$ such that
	\[
	M(\omega', F'') = \PP(X'' \in F'' \mid X' = \omega') \qquad\text{for all $F'' \in \FF''$ and $\PP(X' \in \cdot)$-almost all $\omega' \in \Omega'$}. 
	\]
\end{theorem}

We now consider the marginal density function of jointly distributed random variables:
\begin{lemma}
	Let $U, Y$ be random variables with joint distribution $\PP((U, Y) \in \cdot)$, which is absolutely continuous w.r.t.\ a $\sigma$-finite measure $\nu$ on $(\XX \times\YY, \BB\XX \otimes \BB\YY)$. Assume that $\nu = \nu_U \otimes \nu_Y$ and that $(\XX, \BB\XX, \nu_U)$ and $(\YY, \BB\YY, \nu_Y)$ are $\sigma$-finite. Writing $g_{U, Y} \ceq \frac{\dd \PP((U, Y) \in \cdot)}{\dd\nu}$, we have
	\[
	\PP(U \in \cdot) \ll \nu_U, \quad \PP(Y \in \cdot) \ll \nu_Y, 
	\]
	with probability density functions
	\begin{align*}
		g_U &\ceq \int_\YY g_{U, Y} \dd{\nu_Y} = \frac{\dd \PP(U \in \cdot)}{\dd \nu_U}, \\
		g_Y &\ceq \int_\XX g_{U, Y} \dd{\nu_U} = \frac{\dd \PP(Y \in \cdot)}{\dd \nu_Y}.
	\end{align*}
\end{lemma}

We can use the above theorem to consider the density function of $U$ conditional on $Y$:
\begin{theorem}\label{thm:conditional_density}
	% TODO niet helemaal hetzelfde als thm 6.3.10 maar whatever
	Under the assumptions of the previous lemma, we have $\PP(U \in \cdot \mid Y = y) \ll \nu_U$, and its $\nu_U$ density is
	\[
	g_{U \mid Y = y}(u) = \ind_{g_Y(y) > 0}  \frac{g_{U, Y}(u, y)}{g_Y(y)},
	\]
	which is uniquely defined up to null sets. 
\end{theorem}

\begin{definition}
	Let $g_U, g_Y, g_{U, Y}, g_{U\mid Y= y}, g_{Y \mid U = u}$ be the probability densities from the previous theorem. Then $g_U$ is called the \emph{marginal probability density} of $U$, $g_{U, Y}$ is called the \emph{joint probability density} of $U$ and $Y$, and $g_{U \mid Y = y}$ is called the \emph{conditional density} of $U$ given $Y = y$.  
\end{definition}

\subsection{Bayesian statistics}
\subsubsection{Statistical models}
\begin{definition}
	Let $\XX, \YY$ be separable Banach spaces. We call $\XX$ the \emph{parameter space} and $\YY$ the \emph{data space}. Let $\Pp \ceq \qty{M(\cdot \mid u) : u \in \XX}$, where $M$ is a Markov kernel from $(\XX, \BB\XX)$ to $(\YY, \BB\YY)$. The tuple $(\YY, \Pp)$ is called the \emph{statistical model}. 
\end{definition}

Usually, we distinguish between \emph{parametric models} (where $\XX$ is finite-dimensional) and \emph{nonparametric models}. However, in Bayesian statistics, this distinction rarely matters.

Given a ``true'' parameter $u^* \in \XX$, a distribution $Y \sim M(\cdot \mid u^*)$ and a realisation $y$ of $Y$, we aim to find $u^*$ based on $y$. The probability measure $M(\cdot \mid u^*)$ is called the \emph{data-generating distribution}. 

\begin{definition}
	Let $(\YY, \Pp)$ be a statistical model and $L \colon (\XX \times \YY, \BB\XX \otimes \BB\YY) \to (\RR, \BB\RR)$ such that
	\[
	\Pp = \qty{F \mapsto \int_F L(y \mid u) \dd\mu(y) : u \in \XX}
	\]
	for some measure $\mu$ on $(\YY, \BB\YY)$. Then $L$ is called the \emph{(data) likelihood}. 
\end{definition}
The likelihood is a conditional density $g_{Y\mid U = u}$ for some random variable $U$. 

\subsubsection{Bayes' formula}
Assume we are given a likelihood $L = f_{Y \mid U = u}$ for some $U$. We are interested in finding $f_{U \mid Y = y}$, the posterior density function of $U$. For this we use Bayes's formula:
\begin{theorem}[Bayes]
	Let $U, Y$ be random variables as in \cref{thm:conditional_density}. Then we have
	\[
	g_{U \mid Y =y}(u) = \frac{g_{Y \mid U = u}(y) g_{U}(u)}{g_Y(y)}
	\]
	for $u \in \XX$, $\nu_U$-a.e., and $y \in \YY$, $\PP(Y \in \cdot)$-a.e.\ with $g_Y(y) > 0$. 
\end{theorem}

\begin{definition}
	In the formulation of Bayes' formula: 
	\begin{enumerate}
		\item $Z(y) \ceq g_{Y}(y)$ is called the \emph{model evidence} or \emph{marginal likelihood};
		\item $L(y\mid u) \ceq g_{Y\mid U =u}(y)$ is called the \emph{(data) likelihood};
		\item $\mu_0 \ceq \PP(U \in \cdot)$ is called the \emph{prior measure};
		\item $\mu_\Rm{post} \ceq \PP(U \in \cdot \mid Y = y)$ is called the \emph{posterior measure}. 
	\end{enumerate}
\end{definition}

If we assume that $\nu_U \ceq \mu_0$ (we can choose $\nu_U$ freely so long as $\mu_0$ has a probability density w.r.t.\ $\nu_0$), we obtain from Bayes' formula the formulation
\[
\dv{\mu_\Rm{post}}{\mu_0}(u) = \frac{L(y \mid u)}{Z(y)} \qquad(\mu_0\text{-a.s.}).
\] 
If $\mu_0$ has a density with respect to some other measure $\nu$ (say, Lebesgue measure), then we obtain
\[
\dv{\mu_\Rm{post}}{\nu} = \dv{\mu_\Rm{post}}{\mu_0} \dv{\mu_0}{\nu} = \frac{L(y \mid u)}{Z(y)} \dv{\mu_0}{\nu}. 
\]
In practice, this means that computing the density of the posterior measure comes down to multiplying the likelihood with the prior measure and normalising accordingly. 
